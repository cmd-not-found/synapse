{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "try:\n",
    "    from synapse.lib.jupyter import *\n",
    "except ImportError as e:\n",
    "    # Insert the root path of the repository to sys.path.\n",
    "    # This assumes the notebook is located three directories away\n",
    "    # From the root synapse directory. It may need to be varied\n",
    "    synroot = os.path.abspath('../../../')\n",
    "    sys.path.insert(0, synroot)\n",
    "    from synapse.lib.jupyter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# Create a cortex\n",
    "core = await getTempCoreCmdr()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. highlight:: none\n",
    "\n",
    ".. _storm-ref-automation:\n",
    "\n",
    "Storm Reference - Automation\n",
    "============================\n",
    "\n",
    ".. _auto-bkgd:\n",
    "\n",
    "Background\n",
    "----------\n",
    "\n",
    "Synapse is designed to facilitate large-scale analysis over disparate data sources with speed and efficiency. Many of the features that support this analysis are built into Synapse’s architecture, from performance-optimized indexing and storage to an extensible data model that allows you to reason over data in a structured manner.\n",
    "\n",
    "Synapse also supports large-scale analysis through the use of **automation.** Synapse’s automation features are available through the Storm runtime and include:\n",
    "\n",
    "- `Triggers and Cron`_\n",
    "- `Macros`_\n",
    "\n",
    "Triggers, cron, and macros in Synapse all utilize the Storm query language. That is, regardless of the type of automation used, the result is the execution of a predefined Storm query. This means that **anything that can be written in Storm can be automated,** from the simple and straightforward to the highly complex. Actions performed via automation are limited only by imagination and Storm proficiency. Some automation is fairly simple (\"if X occurs, do Y\" or \"once a week, update Z\"). However, automation can take advantage of all available Storm features, including subqueries, variables, libraries, control flow logic, and so on.\n",
    "\n",
    ".. _auto-consid:\n",
    "\n",
    "Considerations\n",
    "--------------\n",
    "\n",
    "This section is not meant to be a detailed guide on implementing automation. However, a few areas are included here for consideration when utilizing automation in your environment.\n",
    "\n",
    "**Permissions.**\n",
    "\n",
    "The ability to create, modify, or delete triggers, cron jobs, and macros depends on a user having the appropriate permissions to do so. If you assign permissions for these tasks in your environment, keep the following in mind:\n",
    "\n",
    "- Triggers and cron jobs execute in the context of (with the permissions of) **the user who creates them.**\n",
    "\n",
    "- Macros execute in the context of **the user who calls them** for execution, regardless of who created them.\n",
    "\n",
    "The Storm query executed by a given automation task (whether trigger, cron, or macro) cannot perform tasks that it does not have appropriate permissions to perform. This leads to some straightforward (and some less straightforward) situations. For example:\n",
    "\n",
    "- A user with higher privileges can write a macro that can be called and executed by a user with lower privileges. However, if the lower-privileged user does not have permissions to perform actions encoded in the macro, execution by the lower-privileged user will fail (i.e., with an ``AuthDeny`` error).\n",
    "\n",
    "- A user with higher privileges can write a trigger that calls a macro. Because the macro was called by the trigger, the macro executes with the permissions of the user who wrote the trigger. As triggers are event-driven (see below), this means it is possible for a lower-privileged user to cause an event that fires the higher-privileged trigger that calls the higher-privileged macro. Both will execute as written even though the execution was \"caused\" by a lower-privileged user.\n",
    "\n",
    "**Use Cases.**\n",
    "\n",
    "Organizations can implement automation in any way they see fit, and at any scale. Some automation may be enterprise wide, where triggers, cron, and / or macros are used to automate tasks to support an organization’s overall mission or analysis efforts. Other automation may be put in place by individual analysts to support their own research efforts, either on an ongoing or temporary basis. For example:\n",
    "\n",
    "- an analyst may write a cron job to execute a long-running data collection and analysis task during off-peak hours, or may create a macro as a \"shortcut\" to make it easier to store and execute a particular Storm query on demand.\n",
    "\n",
    "- an organization may implement a set of triggers, cron jobs, and macros to track malicious indicators within Synapse and orchestrate the integration of those indicators with security devices or SIEM systems.\n",
    "\n",
    "**Architecture.**\n",
    "\n",
    "There are varying approaches for \"how\" to write and implement automation. For example:\n",
    "\n",
    "- Triggers, cron, and macros can be kept entirely separate and independent from one another, each executing their own Storm code and performing different tasks. Alternately, automation can be somewhat centralized within macros, where triggers and cron (when used) execute minimal Storm queries whose purpose is to call more extensive Storm stored in macros.\n",
    "\n",
    "- Automation can be written as many small, individual elements that each perform a relatively simple task, but which are designed to work together like building blocks to orchestrate larger-scale operations. In contrast, automation can be implemented using fewer elements that perform larger, more unified tasks using more complex Storm to carry out multiple operations.\n",
    "\n",
    "Each approach has its pros and cons; there is no single \"right\" way, and what works best in your environment or for a particular task will depend on your needs (and possibly some trial and error).\n",
    "\n",
    "**Governance / Management.**\n",
    "\n",
    "Where multiple users have the ability to create automation tasks, it is possible for them to create duplicative or even conflicting automation. This is less likely to occur (or less likely to be potentially harmful) when users create automation to support their personal workflow, but can present problems where multiple users have permissions to both create automation and perform actions within Synapse that have \"global\" effects. For example:\n",
    "\n",
    "- Tags typically represent assessments about data. This can include things like whether an IP address is a sinkhole or whether an indicator is associated with a particular threat group. Organizations may wish to consider under what circumstances these assessments should be applied via automation. (For organizations not comfortable with fully automating certain analytical decisions, automation can be used to tag something \"for review\" to ensure a human in the loop.)\n",
    "\n",
    "- Automation is particularly useful for \"enriching\" indicators (such as domains or file hashes) by ingesting data into Synapse from various third-party sources. In some cases third-party access may be subject to daily query limits or may incur per-query (or per-result) usage costs. Organizations may wish to consider how to balance the convenience of automation with potential operational or financial impacts.\n",
    "\n",
    "Organizations should plan whether or how to coordinate and deconflict automation where appropriate.\n",
    "\n",
    "**Review and Testing.**\n",
    "\n",
    "Automation in Synapse provides significant advantages. It removes the burden of performing tedious tasks from analysts, freeing them to focus on more detailed analysis and complex tasks. It also allows you to scale your analytical operations by limiting the amount of work that must be performed manually. However, badly written automation or automation that contains logical errors also allows you to \"make errors at machine speed\". We strongly encourage testing automation in a development environment before implementing it on a production system.\n",
    "\n",
    "**Nodes In and Nodes Out.**\n",
    "\n",
    "In some cases automation can be used to \"chain\" operations (e.g., both triggers and cron can call macros) or may be executed inline with other Storm operations (a macro can be called in the middle of a Storm query where the query expects to perform further operations on the nodes returned by the macro). In these cases, both the automation itself and any Storm executed after the automation may fail if the inbound nodes are not what is expected by the query.\n",
    "\n",
    "Users should keep the :ref:`storm-op-concepts` in mind when writing automation.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _auto-triggers-cron:\n",
    "\n",
    "Triggers and Cron\n",
    "-----------------\n",
    "\n",
    "Triggers and cron are similar in terms of permissions and management. Both triggers and cron:\n",
    "\n",
    "- **Support permissions.** Synapse uses permissions to determine who can create, modify, and delete triggers and cron jobs. Triggers and cron jobs execute **with the permissions of the user who creates them.** (This is fairly intuitive for cron, but may be less so in the case of triggers.) Conversely, a trigger or cron job can only perform actions that their creator has permissions to perform.\n",
    "\n",
    "- **Are introspectable.** Triggers and cron jobs are created as run-time nodes (\"runt nodes\") and can be lifted, filtered, and pivoted across just like other elements of the Synapse data model (see the :ref:`storm-ref-model-introspect` guide for details).\n",
    "\n",
    "- **Are view-specific.** Synapse allows the optional segregation of data in a Cortex into multiple :ref:`gloss-layer`s that can be \"stacked\" to provide a unified ::ref:`gloss-view` of data to users. Triggers and cron jobs are specific to a view. This means that they are carried over (for example) if a user forks a view. See the :ref:`storm-layer` and :ref:`storm-view` commands in the :ref:`storm-ref-cmd` guide for additional detail on working with views and layers.\n",
    "\n",
    ".. INFO::\n",
    "\n",
    "  A simple Synapse implementation consists of a single Cortex with a single layer and a single view.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _auto-triggers:\n",
    "\n",
    "Triggers\n",
    "++++++++\n",
    "\n",
    "Triggers are **event-driven.** As their name implies, they trigger (\"fire\") their associated Storm query on demand when specific events occur in a Cortex. As noted above, a trigger executes with the permissions of the user who created it; the trigger can only perform actions that the user is allowed to perform.\n",
    "\n",
    "Triggers can fire on the following events:\n",
    "\n",
    "- Adding a node (``node:add``)\n",
    "- Deleting a node (``node:del``)\n",
    "- Setting a property (``prop:set``)\n",
    "- Adding a tag to a node (``tag:add``)\n",
    "- Deleting a tag from a node (``tag:del``)\n",
    "\n",
    "Each event requires an object (a form, property, or tag) to act upon - that is, if you write a trigger to fire on a ``node:add`` event, you must specify the type of node (form) associated with the event. Similarly, if a trigger should fire on a ``tag:del`` event, you must specify the tag whose removal fires the trigger.\n",
    "\n",
    "``tag:add`` and ``tag:del`` events can take an optional form, allowing you to specify events that fire when a given tag is added (or removed) from a specific form as opposed to any / all forms.\n",
    "\n",
    ".. INFO::\n",
    "  With respect to triggers, node creation within Synapse is atomic; that is, creating a node and setting any secondary properties is treated as a single operation. This is done to avoid race conditions where (for example) a trigger that fires on a ``node:add`` event depends on the existence of a secondary property that has not yet been set.\n",
    "\n",
    "Triggers execute **immediately** when their associated event occurs in a Cortex. This allows automation to occur in \"real time\" as opposed to waiting for a scheduled cron job to execute (or for an analyst to manually perform some task). As such, triggers are most appropriate for automating tasks that should occur right away (e.g., based on efficiency or importance). For example, triggers can be used to perform simple but tedious tasks, freeing analysts from having to perform such tasks manually; or they can be used to collect additional data (e.g., from third-party services) about nodes of interest (\"enrich\" those nodes).\n",
    "\n",
    ".. WARNING::\n",
    "  Triggers execute **inline** with the process (typically a Storm query) that causes them to fire. That is, if a process (or an analyst) creates a node as part of a longer Storm query and creation of that node causes a trigger to fire, the trigger’s Storm will execute immediately and in full before returning \"back\" to the main query to complete any additional Storm operations. This includes execution of any additional code that may be called by the trigger itself, such as a macro. Conceptually, it is as though all of the trigger’s Storm code and any additional Storm that it calls were inserted into the middle of the original Storm query that fired the trigger.\n",
    "  \n",
    "  This inline execution can impact a Cortex’s performance, depending on the Storm executed by the trigger and the number of nodes causing the trigger to fire. For example, let’s say you are using CSVTool (see :ref:`syn-tools-csvtool`) to load 3,000 indicators and tag them as \"malicious\". Your Cortex includes a trigger that fires when a \"malicious\" tag is applied to any node, calling a Storm query that contacts five third-party services to enrich those indicators, resulting in the creation of dozens of additional nodes for each indicator enriched. This tag-and-enrich process is executed inline for each of the 3,000 nodes created by the CSVTool ingest.\n",
    "\n",
    "Conversely, triggers **only** execute when the specified event occurs. The events used to fire triggers typically will only ever occur once - the node ``inet:fqdn=woot.com`` will only ever be added to a Cortex once; applying the tag ``#my.tag`` to a ``hash:md5`` node will only occur one time (barring deleting and later re-adding the node or tag). The only exception is the ``prop:set`` event, which will fire when the specified property is first set (often on node creation) as well as any time the property is modified (i.e., \"set\" again).\n",
    "\n",
    "The \"one-time\" nature of triggers may result in a small number of edge cases where the trigger does not perform the desired action. For example:\n",
    "\n",
    "- Triggers do not operate retroactively; they will not fire for nodes that already exist in a Cortex at the time the trigger is added. That is, if you write a new trigger to fire any time the tag ``#my.tag`` is applied to a ``hash:md5`` node, the trigger will have no effect on existing ``hash:md5`` nodes that already have the tag.\n",
    "- If a trigger depends on a resource (process, service, etc.) that is not available when it fires, the trigger will simply fail; it will not \"try again\".\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "Triggers are created, modified, viewed, enabled, disabled, and deleted using the Storm ``trigger.*``  commands. See the :ref:`storm-trigger` command in the :ref:`storm-ref-cmd` document for details.\n",
    "\n",
    ".. NOTE::\n",
    "  Triggers can be modified after they are created, but modification is limited to updating the Storm query executed by the trigger. If other aspects of a trigger need to be changed (such as the event that fires the trigger, or the form a trigger operates on), the trigger must be deleted and re-created.\n",
    "\n",
    "**Examples:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _auto-cron:\n",
    "\n",
    "Cron\n",
    "++++\n",
    "\n",
    "TBD\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _auto-macros:\n",
    "\n",
    "Macros\n",
    "------\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "# Close cortex because done\n",
    "_ = await core.fini()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
